{
	"$schema": "http://schema.management.azure.com/schemas/2015-01-01/deploymentTemplate.json#",
	"contentVersion": "1.0.0.0",
	"parameters": {
		"workspaceName": {
			"type": "string",
			"metadata": "Arbeitsbereichsname",
			"defaultValue": "testsynapsepoc"
		},
		"AzureSqlDatabase1_connectionString": {
			"type": "secureString",
			"metadata": "Sichere Zeichenfolge für \"connectionString\" von \"AzureSqlDatabase1\""
		},
		"linkedService1_accountKey": {
			"type": "secureString",
			"metadata": "Sichere Zeichenfolge für \"accountKey\" von \"linkedService1\""
		},
		"testsynapsepoc-WorkspaceDefaultSqlServer_connectionString": {
			"type": "secureString",
			"metadata": "Sichere Zeichenfolge für \"connectionString\" von \"testsynapsepoc-WorkspaceDefaultSqlServer\""
		},
		"linkedService1_properties_typeProperties_url": {
			"type": "string",
			"defaultValue": "https://datalalakesynapse1.dfs.core.windows.net"
		},
		"testsynapsepoc-WorkspaceDefaultStorage_properties_typeProperties_url": {
			"type": "string",
			"defaultValue": "https://datalalakesynapse1.dfs.core.windows.net"
		},
		"TriggerDatalakeChange_properties_typeProperties_scope": {
			"type": "string",
			"defaultValue": "/subscriptions/81c0eba5-b65a-4f50-8c57-6e7e82e459c0/resourceGroups/RG_Databrick_Test/providers/Microsoft.Storage/storageAccounts/datalalakesynapse1"
		}
	},
	"variables": {
		"workspaceId": "[concat('Microsoft.Synapse/workspaces/', parameters('workspaceName'))]"
	},
	"resources": [
		{
			"name": "[concat(parameters('workspaceName'), '/Pipeline 1')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"activities": [
					{
						"name": "Copy Database1 auf SQLPoolTest",
						"type": "Copy",
						"dependsOn": [],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"source": {
								"type": "AzureSqlSource",
								"queryTimeout": "02:00:00",
								"partitionOption": "None"
							},
							"sink": {
								"type": "SqlPoolSink",
								"allowPolyBase": true,
								"polyBaseSettings": {
									"rejectValue": 0,
									"rejectType": "value",
									"useTypeDefault": true
								},
								"tableOption": "autoCreate"
							},
							"enableStaging": true,
							"stagingSettings": {
								"linkedServiceName": {
									"referenceName": "linkedService1",
									"type": "LinkedServiceReference"
								}
							}
						},
						"inputs": [
							{
								"referenceName": "AzureSqlTable1",
								"type": "DatasetReference",
								"parameters": {}
							}
						],
						"outputs": [
							{
								"referenceName": "SqlPoolTable1",
								"type": "DatasetReference",
								"parameters": {}
							}
						]
					}
				],
				"annotations": []
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/datasets/AzureSqlTable1')]",
				"[concat(variables('workspaceId'), '/datasets/SqlPoolTable1')]",
				"[concat(variables('workspaceId'), '/linkedServices/linkedService1')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Pipeline 2')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"activities": [
					{
						"name": "Read_and_save_Data",
						"type": "SynapseNotebook",
						"dependsOn": [],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"notebook": {
								"referenceName": "Read_and_save_Data",
								"type": "NotebookReference"
							},
							"parameters": {
								"DataAdded": {
									"value": {
										"value": "@pipeline().parameters.Folderpath",
										"type": "Expression"
									},
									"type": "string"
								}
							},
							"snapshot": true
						}
					}
				],
				"parameters": {
					"Folderpath": {
						"type": "string",
						"defaultValue": "@triggerBody().folderPath"
					}
				},
				"annotations": []
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/notebooks/Read_and_save_Data')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/AzureSqlTable1')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "AzureSqlDatabase1",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "AzureSqlTable",
				"schema": [
					{
						"name": "name",
						"type": "varchar"
					},
					{
						"name": "prename",
						"type": "varchar"
					},
					{
						"name": "age",
						"type": "int",
						"precision": 10
					}
				],
				"typeProperties": {
					"schema": "dbo",
					"table": "Personen"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/AzureSqlDatabase1')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/SqlPoolTable1')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "SqlPoolTable",
				"schema": [
					{
						"name": "ID",
						"type": "int",
						"precision": 10
					},
					{
						"name": "Vorname",
						"type": "varchar"
					},
					{
						"name": "Nachname",
						"type": "varchar"
					}
				],
				"typeProperties": {
					"schema": "dbo",
					"table": "Personen"
				},
				"sqlPool": {
					"referenceName": "SQLPoolTest",
					"type": "SqlPoolReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/sqlPools/SQLPoolTest')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/AzureSqlDatabase1')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "AzureSqlDatabase",
				"typeProperties": {
					"connectionString": "[parameters('AzureSqlDatabase1_connectionString')]"
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/linkedService1')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "AzureBlobFS",
				"typeProperties": {
					"url": "[parameters('linkedService1_properties_typeProperties_url')]",
					"accountKey": {
						"type": "SecureString",
						"value": "[parameters('linkedService1_accountKey')]"
					}
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/testsynapsepoc-WorkspaceDefaultSqlServer')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"parameters": {
					"DBName": {
						"type": "String"
					}
				},
				"annotations": [],
				"type": "AzureSqlDW",
				"typeProperties": {
					"connectionString": "[parameters('testsynapsepoc-WorkspaceDefaultSqlServer_connectionString')]"
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/testsynapsepoc-WorkspaceDefaultStorage')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "AzureBlobFS",
				"typeProperties": {
					"url": "[parameters('testsynapsepoc-WorkspaceDefaultStorage_properties_typeProperties_url')]"
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/TriggerDatalakeChange')]",
			"type": "Microsoft.Synapse/workspaces/triggers",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"runtimeState": "Started",
				"pipelines": [
					{
						"pipelineReference": {
							"referenceName": "Pipeline 2",
							"type": "PipelineReference"
						},
						"parameters": {}
					}
				],
				"type": "BlobEventsTrigger",
				"typeProperties": {
					"blobPathBeginsWith": "/synapsecontainter1/blobs/",
					"ignoreEmptyBlobs": true,
					"scope": "[parameters('TriggerDatalakeChange_properties_typeProperties_scope')]",
					"events": [
						"Microsoft.Storage.BlobCreated"
					]
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/pipelines/Pipeline 2')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Wiederholung')]",
			"type": "Microsoft.Synapse/workspaces/triggers",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"runtimeState": "Stopped",
				"pipelines": [
					{
						"pipelineReference": {
							"referenceName": "Pipeline 2",
							"type": "PipelineReference"
						},
						"parameters": {}
					}
				],
				"type": "ScheduleTrigger",
				"typeProperties": {
					"recurrence": {
						"frequency": "Minute",
						"interval": 30,
						"startTime": "2021-07-09T10:25:00Z",
						"endTime": "2021-07-12T10:25:00Z",
						"timeZone": "UTC"
					}
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/pipelines/Pipeline 2')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/AutoResolveIntegrationRuntime')]",
			"type": "Microsoft.Synapse/workspaces/integrationRuntimes",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"type": "Managed",
				"typeProperties": {
					"computeProperties": {
						"location": "AutoResolve",
						"dataFlowProperties": {
							"computeType": "General",
							"coreCount": 8,
							"timeToLive": 0
						}
					}
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/WorkspaceSystemIdentity')]",
			"type": "Microsoft.Synapse/workspaces/credentials",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"type": "ManagedIdentity",
				"typeProperties": {}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/SQL script 1')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"content": {
					"query": "select * from dbo.Personen",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"poolName": "SQLPoolTest",
						"databaseName": "SQLPoolTest"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Notebook 1')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "sparkpool1",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "56g",
					"driverCores": 8,
					"executorMemory": "56g",
					"executorCores": 8,
					"numExecutors": 2,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2"
					}
				},
				"metadata": {
					"saveOutput": true,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/81c0eba5-b65a-4f50-8c57-6e7e82e459c0/resourceGroups/RG_Databrick_Test/providers/Microsoft.Synapse/workspaces/testsynapsepoc/bigDataPools/sparkpool1",
						"name": "sparkpool1",
						"type": "Spark",
						"endpoint": "https://testsynapsepoc.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/sparkpool1",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net"
						},
						"sparkVersion": "2.4",
						"nodeCount": 10,
						"cores": 8,
						"memory": 56
					}
				},
				"cells": [
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": true
						},
						"source": [
							"# Defining the service principal credentials for the Azure storage account\r\n",
							"spark.conf.set(\"fs.azure.account.auth.type\", \"OAuth\")\r\n",
							"spark.conf.set(\"fs.azure.account.oauth.provider.type\",  \"org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider\")\r\n",
							"spark.conf.set(\"fs.azure.account.oauth2.client.id\", \"<application-id>\")\r\n",
							"spark.conf.set(\"fs.azure.account.oauth2.client.secret\", \"<service-credential>\")\r\n",
							"spark.conf.set(\"fs.azure.account.oauth2.client.endpoint\", \"https://login.microsoftonline.com/<directory-id>/oauth2/token\")\r\n",
							"\r\n",
							"# Defining a separate set of service principal credentials for Azure Synapse Analytics (If not defined, the connector will use the Azure storage account credentials)\r\n",
							"spark.conf.set(\"spark.databricks.sqldw.jdbc.service.principal.client.id\", \"<application-id>\")\r\n",
							"spark.conf.set(\"spark.databricks.sqldw.jdbc.service.principal.client.secret\", \"<service-credential>\")"
						],
						"outputs": [],
						"execution_count": 22
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": true
						},
						"source": [
							"spark.conf.set(\r\n",
							"  \"fs.azure.account.key.<your-storage-account-name>.blob.core.windows.net\",\r\n",
							"  \"dVCpKzceqhS6yukyP4fzeVwU1W2xjelaSZZH6/tekoeemWaGuE7ZCifJEyjrF39N8tg3JZwaFGYgz2/hDbwtyw==\")"
						],
						"outputs": [],
						"execution_count": 23
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": true
						},
						"source": [
							"sc._jsc.hadoopConfiguration().set(\r\n",
							"  \"fs.azure.account.key.datalalakesynapse1.blob.core.windows.net\",\r\n",
							"  \"dVCpKzceqhS6yukyP4fzeVwU1W2xjelaSZZH6/tekoeemWaGuE7ZCifJEyjrF39N8tg3JZwaFGYgz2/hDbwtyw==\")"
						],
						"outputs": [],
						"execution_count": 24
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": true
						},
						"source": [
							"df = spark.read.option(\"header\",\"true\").option(\"inferSchema\",\"true\").option(\"delimiter\",\",\").csv(f\"wasbs://synapsecontainter1@datalalakesynapse1.blob.core.windows.net/Personen.CSV\")"
						],
						"outputs": [],
						"execution_count": 25
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": true
						},
						"source": [
							"df.show()"
						],
						"outputs": [],
						"execution_count": 35
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"df.createOrReplaceTempView(\"personendftemptable\")"
						],
						"outputs": [],
						"execution_count": 27
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"microsoft": {
								"language": "scala"
							},
							"collapsed": true
						},
						"source": [
							"%%spark\r\n",
							"val scala_df = spark.sqlContext.sql (\"select * from pysparkdftemptable\")\r\n",
							"\r\n",
							"scala_df.write.synapsesql(\"SQLPoolTest.dbo.PySparkTable\", Constants.INTERNAL)"
						],
						"outputs": [],
						"execution_count": 49
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Notebook 2')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "sparkpool1",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "56g",
					"driverCores": 8,
					"executorMemory": "56g",
					"executorCores": 8,
					"numExecutors": 2,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2"
					}
				},
				"metadata": {
					"saveOutput": true,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/81c0eba5-b65a-4f50-8c57-6e7e82e459c0/resourceGroups/RG_Databrick_Test/providers/Microsoft.Synapse/workspaces/testsynapsepoc/bigDataPools/sparkpool1",
						"name": "sparkpool1",
						"type": "Spark",
						"endpoint": "https://testsynapsepoc.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/sparkpool1",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net"
						},
						"sparkVersion": "2.4",
						"nodeCount": 10,
						"cores": 8,
						"memory": 56
					}
				},
				"cells": [
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": true
						},
						"source": [
							"spark.conf.set(\r\n",
							"  \"fs.azure.account.key.datalalakesynapse1.blob.core.windows.net\",\r\n",
							"  \"dVCpKzceqhS6yukyP4fzeVwU1W2xjelaSZZH6/tekoeemWaGuE7ZCifJEyjrF39N8tg3JZwaFGYgz2/hDbwtyw==\")"
						],
						"outputs": [],
						"execution_count": 8
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": true
						},
						"source": [
							"spark.conf.set(\r\n",
							"  \"fs.azure.account.key.datalalakesynapse1.blob.core.windows.net\",\r\n",
							"  \"dVCpKzceqhS6yukyP4fzeVwU1W2xjelaSZZH6/tekoeemWaGuE7ZCifJEyjrF39N8tg3JZwaFGYgz2/hDbwtyw==\")"
						],
						"outputs": [],
						"execution_count": 9
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": true
						},
						"source": [
							"# spark is an existing SparkSession\r\n",
							"df = spark.read.option(\"header\",\"true\").option(\"inferSchema\",\"true\").option(\"delimiter\",\",\").csv(f\"wasbs://synapsecontainter1@datalalakesynapse1.blob.core.windows.net/Personen.CSV\")\r\n",
							"# Displays the content of the DataFrame to stdout\r\n",
							"df.show()"
						],
						"outputs": [],
						"execution_count": 10
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": true
						},
						"source": [
							"df.createOrReplaceTempView(\"pysparkdftemptable\")"
						],
						"outputs": [],
						"execution_count": 11
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"microsoft": {
								"language": "scala"
							},
							"collapsed": true
						},
						"source": [
							"%%spark\r\n",
							"val scala_df = spark.sqlContext.sql (\"select * from pysparkdftemptable\")\r\n",
							"\r\n",
							"scala_df.write.synapsesql(\"sqlpool.dbo.PySparkTable\", Constants.INTERNAL)"
						],
						"outputs": [],
						"execution_count": 12
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"microsoft": {
								"language": "scala"
							},
							"collapsed": true
						},
						"source": [
							"%%spark\r\n",
							"import com.microsoft.azure.sqldb.spark.config.Config\r\n",
							"import com.microsoft.azure.sqldb.spark.connect._\r\n",
							"\r\n",
							"val config = Config(Map(\r\n",
							"  \"url\"            -> \"testsynapsepoc.database.windows.net\",\r\n",
							"  \"databaseName\"   -> \"SQLPoolTest\",\r\n",
							"  \"dbTable\"        -> \"dbo.Personen\",\r\n",
							"  \"user\"           -> \"pft6fe\",\r\n",
							"  \"password\"       -> \"\",\r\n",
							"  \"connectTimeout\" -> \"5\", //seconds\r\n",
							"  \"queryTimeout\"   -> \"5\"  //seconds\r\n",
							"))\r\n",
							"\r\n",
							"val collection = sqlContext.read.sqlDB(config)\r\n",
							"collection.show()"
						],
						"outputs": [],
						"execution_count": 13
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Notebook 3')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "sparkpool1",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "56g",
					"driverCores": 8,
					"executorMemory": "56g",
					"executorCores": 8,
					"numExecutors": 2,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2"
					}
				},
				"metadata": {
					"saveOutput": true,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/81c0eba5-b65a-4f50-8c57-6e7e82e459c0/resourceGroups/RG_Databrick_Test/providers/Microsoft.Synapse/workspaces/testsynapsepoc/bigDataPools/sparkpool1",
						"name": "sparkpool1",
						"type": "Spark",
						"endpoint": "https://testsynapsepoc.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/sparkpool1",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net"
						},
						"sparkVersion": "2.4",
						"nodeCount": 10,
						"cores": 8,
						"memory": 56
					}
				},
				"cells": [
					{
						"cell_type": "code",
						"metadata": {
							"microsoft": {
								"language": "python"
							},
							"collapsed": false
						},
						"source": [
							"%%pyspark\r\n",
							"df = spark.read.load('abfss://synapsecontainter1@datalalakesynapse1.dfs.core.windows.net/Personen.CSV', format='csv'\r\n",
							"## If header exists uncomment line below\r\n",
							"##, header=True\r\n",
							")\r\n",
							"display(df.limit(10))"
						],
						"outputs": [],
						"execution_count": 1
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": true
						},
						"source": [
							"df.show()"
						],
						"outputs": [],
						"execution_count": 2
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": true
						},
						"source": [
							"df.createOrReplaceTempView(\"personendftemptable\")"
						],
						"outputs": [],
						"execution_count": 3
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"microsoft": {
								"language": "scala"
							},
							"collapsed": true
						},
						"source": [
							"%%spark\r\n",
							"val scala_df = spark.sqlContext.sql (\"select * from personendftemptable\")\r\n",
							"\r\n",
							"scala_df.write.synapsesql(\"SQLPoolTest.dbo.PySparkTable\", Constants.INTERNAL)"
						],
						"outputs": [],
						"execution_count": 4
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Notebook 4')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "sparkpool1",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "56g",
					"driverCores": 8,
					"executorMemory": "56g",
					"executorCores": 8,
					"numExecutors": 2,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2"
					}
				},
				"metadata": {
					"saveOutput": true,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "python"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/81c0eba5-b65a-4f50-8c57-6e7e82e459c0/resourceGroups/RG_Databrick_Test/providers/Microsoft.Synapse/workspaces/testsynapsepoc/bigDataPools/sparkpool1",
						"name": "sparkpool1",
						"type": "Spark",
						"endpoint": "https://testsynapsepoc.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/sparkpool1",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net"
						},
						"sparkVersion": "2.4",
						"nodeCount": 10,
						"cores": 8,
						"memory": 56
					}
				},
				"cells": [
					{
						"cell_type": "code",
						"metadata": {
							"tags": [
								"parameters"
							]
						},
						"source": [
							"DataAdded = @triggerBody().folderName"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": true
						},
						"source": [
							"print(DataAdded);"
						],
						"outputs": [],
						"execution_count": null
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Read_and_save_Data')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "sparkpool1",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "56g",
					"driverCores": 8,
					"executorMemory": "56g",
					"executorCores": 8,
					"numExecutors": 2,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2"
					}
				},
				"metadata": {
					"saveOutput": true,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/81c0eba5-b65a-4f50-8c57-6e7e82e459c0/resourceGroups/RG_Databrick_Test/providers/Microsoft.Synapse/workspaces/testsynapsepoc/bigDataPools/sparkpool1",
						"name": "sparkpool1",
						"type": "Spark",
						"endpoint": "https://testsynapsepoc.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/sparkpool1",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net"
						},
						"sparkVersion": "2.4",
						"nodeCount": 10,
						"cores": 8,
						"memory": 56,
						"automaticScaleJobs": false
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": true,
							"tags": [
								"parameters"
							]
						},
						"source": [
							"DataAdded = \"Keine Daten vorhanden\""
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"microsoft": {
								"language": "python"
							},
							"collapsed": false
						},
						"source": [
							"%%pyspark\r\n",
							"\r\n",
							"df = spark.read.load(DataAdded, format='csv', \r\n",
							"header=True, delimiter = \";\")\r\n",
							"display(df)"
						],
						"outputs": [],
						"execution_count": 9
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": true
						},
						"source": [
							"df.show()"
						],
						"outputs": [],
						"execution_count": 6
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": true
						},
						"source": [
							"dfwithDataAdded.createOrReplaceTempView(\"ultradurdftemptable\")"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"microsoft": {
								"language": "scala"
							},
							"collapsed": true
						},
						"source": [
							"%%spark\r\n",
							"val scala_df = spark.sqlContext.sql (\"select * from ultradurdftemptable\")\r\n",
							"\r\n",
							"scala_df.write.synapsesql(\"SQLPoolTest.dbo.UltradurTable\", Constants.INTERNAL)"
						],
						"outputs": [],
						"execution_count": 7
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/SQLPoolTest')]",
			"type": "Microsoft.Synapse/workspaces/sqlPools",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"collation": "SQL_Latin1_General_CP1_CI_AS",
				"maxSizeBytes": 263882790666240,
				"restorePointInTime": "0001-01-01T00:00:00",
				"annotations": []
			},
			"dependsOn": [],
			"location": "westeurope"
		}
	]
}